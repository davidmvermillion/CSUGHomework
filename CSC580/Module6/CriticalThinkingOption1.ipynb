{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Define and Train Network",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "a7b579e110b949ae86df0c539f41b32e",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "d853715e6a764728bdf52775398a4d0a"
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nfrom time import time\nimport math\nfrom include.data import get_data_set\nfrom include.model import model, lr\n \ntrain_x, train_y = get_data_set(\"train\")\ntest_x, test_y = get_data_set(\"test\")\ntf.set_random_seed(21)\nx, y, output, y_pred_cls, global_step, learning_rate = model()\nglobal_accuracy = 0\nepoch_start = 0\n \n# PARAMS\n_BATCH_SIZE = 128\n_EPOCH = 60\n_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n \n# LOSS AND OPTIMIZER\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                   beta1=0.9,\n                                   beta2=0.999,\n                                   epsilon=1e-08).minimize(loss, global_step=global_step)\n \n# PREDICTION AND ACCURACY CALCULATION\ncorrect_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n \n# SAVER\nmerged = tf.summary.merge_all()\nsaver = tf.train.Saver()\nsess = tf.Session()\ntrain_writer = tf.summary.FileWriter(_SAVE_PATH, sess.graph)\n  \ntry:\n    print(\"Trying to restore last checkpoint ...\")\n    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n    saver.restore(sess, save_path=last_chk_path)\n    print(\"Restored checkpoint from:\", last_chk_path)\nexcept ValueError:\n    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n    sess.run(tf.global_variables_initializer())\n  \ndef train(epoch):\n    global epoch_start\n    epoch_start = time()\n    batch_size = int(math.ceil(len(train_x) / _BATCH_SIZE))\n    i_global = 0\n \n    for s in range(batch_size):\n        batch_xs = train_x[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n        batch_ys = train_y[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n \n        start_time = time()\n        i_global, _, batch_loss, batch_acc = sess.run(\n            [global_step, optimizer, loss, accuracy],\n            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)})\n        duration = time() - start_time\n \n        if s % 10 == 0:\n            percentage = int(round((s/batch_size)*100))\n \n            bar_len = 29\n            filled_len = int((bar_len*int(percentage))/100)\n            bar = '=' * filled_len + '>' + '-' * (bar_len - filled_len)\n \n            msg = \"Global step: {:>5} - [{}] {:>3}% - acc: {:.4f} - loss: {:.4f} - {:.1f} sample/sec\"\n            print(msg.format(i_global, bar, percentage, batch_acc, batch_loss, _BATCH_SIZE / duration))\n \n    test_and_save(i_global, epoch)\n  \ndef test_and_save(_global_step, epoch):\n    global global_accuracy\n    global epoch_start\n \n    i = 0\n    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n    while i < len(test_x): \n        j = min(i + _BATCH_SIZE, len(test_x)) \n        batch_xs = test_x[i:j, :] \n        batch_ys = test_y[i:j, :] \n        predicted_class[i:j] = sess.run( \n            y_pred_cls, \n            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)} \n            ) \n        i = j \n        correct = (np.argmax(test_y, axis=1) == predicted_class) \n        acc = correct.mean()*100 \n        correct_numbers = correct.sum() \n        hours, rem = divmod(time() - epoch_start, 3600) \n        minutes, seconds = divmod(rem, 60) \n        mes = \" Epoch {} - accuracy: {:.2f}% ({}/{}) - time: {:0>2}:{:0>2}:{:05.2f}\"\n    print(mes.format((epoch+1), acc, correct_numbers, len(test_x), int(hours), int(minutes), seconds))\n \n    if global_accuracy != 0 and global_accuracy < acc: \n        summary = tf.Summary(value=[ tf.Summary.Value(tag=\"Accuracy/test\", simple_value=acc), ]) \n        train_writer.add_summary(summary, _global_step) \n        saver.save(sess, save_path=_SAVE_PATH, global_step=_global_step) \n        mes = \"This epoch receive better accuracy: {:.2f} > {:.2f}. Saving session...\"\n        print(mes.format(acc, global_accuracy))\n        global_accuracy = acc\n \n    elif global_accuracy == 0:\n        global_accuracy = acc\n \n    print(\"###########################################################################################################\")\n  \ndef main():\n    train_start = time()\n \n    for i in range(_EPOCH):\n        print(\"Epoch: {}/{}\".format((i+1), _EPOCH))\n        train(i)\n \n    hours, rem = divmod(time() - train_start, 3600)\n    minutes, seconds = divmod(rem, 60)\n    mes = \"Best accuracy pre session: {:.2f}, time: {:0>2}:{:0>2}:{:05.2f}\"\n    print(mes.format(global_accuracy, int(hours), int(minutes), seconds))\n  \nif __name__ == \"__main__\":\n    main()\n  \nsess.close()",
      "metadata": {
        "source_hash": "681d112f",
        "execution_start": 1729293111944,
        "execution_millis": 155,
        "execution_context_id": "4e3d0099-2537-4939-b2b9-d36b8f6c7b61",
        "cell_id": "3b74cf9f496a4b259466a4ad89e886d4",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'collections' has no attribute 'MutableSet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minclude\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_data_set\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minclude\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model, lr\n\u001b[1;32m      8\u001b[0m train_x, train_y \u001b[38;5;241m=\u001b[39m get_data_set(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/include/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m _IMPORT_HOOKS \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mWeakValueDictionary()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# must have _IMPORT_HOOKS to bootstrap hook disabling\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minhibit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DISABLED_TYPES\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpath\u001b[39m(file_path):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    Include module code from a file identified by its path\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m       my_config = include.path('/etc/sysconfig/app_conf.py')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/include/inhibit.py:198\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DisabledIncludeError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInclude type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m disabled, cannot import module \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module_prefix, name))\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m#: Default interface to disabled types, see :py:class:`DisabledIncludeTypes`\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m DISABLED_TYPES \u001b[38;5;241m=\u001b[39m \u001b[43mDisabledIncludeTypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/venv/lib/python3.10/site-packages/include/inhibit.py:38\u001b[0m, in \u001b[0;36mDisabledIncludeTypes.__new__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_singleton_instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_singleton_instance\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_singleton_instance \u001b[38;5;241m=\u001b[39m \u001b[43mcollections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMutableSet\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_identifier2import_path(identifier\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m identifier \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment_key, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m identifier\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disabled:\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'collections' has no attribute 'MutableSet'"
          ]
        }
      ],
      "outputs_reference": null,
      "execution_count": 8,
      "block_group": "3b74cf9f496a4b259466a4ad89e886d4",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Test Network",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "34494965ea6049f2b6840c246b1948fd",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "55d9c187571a4b1f8c05c6abd51fe0ca"
    },
    {
      "cell_type": "code",
      "source": "test_x, test_y = get_data_set(\"test\")\nx, y, output, y_pred_cls, global_step, learning_rate = model()\n  \n_BATCH_SIZE = 128\n_CLASS_SIZE = 10\n_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n  \nsaver = tf.train.Saver()\nsess = tf.Session()\n  \ntry:\n    print(\"\nTrying to restore last checkpoint ...\")\n    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n    saver.restore(sess, save_path=last_chk_path)\n    print(\"Restored checkpoint from:\", last_chk_path)\nexcept ValueError:\n    print(\"\nFailed to restore checkpoint. Initializing variables instead.\")\n    sess.run(tf.global_variables_initializer())\n  \ndef main():\n    i = 0\n    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n    while i < len(test_x):\n        j = min(i + _BATCH_SIZE, len(test_x))\n        batch_xs = test_x[i:j, :]\n        batch_ys = test_y[i:j, :]\n        predicted_class[i:j] = sess.run(y_pred_cls, feed_dict={x: batch_xs, y: batch_ys})\n        i = j\n \n    correct = (np.argmax(test_y, axis=1) == predicted_class)\n    acc = correct.mean() * 100\n    correct_numbers = correct.sum()\n    print()\n    print(\"Accuracy on Test-Set: {0:.2f}% ({1} / {2})\".format(acc, correct_numbers, len(test_x)))\n  \nif __name__ == \"__main__\":\n    main()\n  \nsess.close()",
      "metadata": {
        "cell_id": "3dd61d3d9feb4ea7b39266ec14062461",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "f2889f6685f54c988f2926a622b2aee3",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3e480598-2102-4b3c-a7af-02aec7eef77c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "5874400f808e4ac9a69d39ec3de827b0",
    "deepnote_execution_queue": []
  }
}