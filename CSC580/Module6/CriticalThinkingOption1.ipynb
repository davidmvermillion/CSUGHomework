{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Define and Train Network",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "a7b579e110b949ae86df0c539f41b32e",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "d853715e6a764728bdf52775398a4d0a"
    },
    {
      "cell_type": "markdown",
      "source": "## Set Environment",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "b141b2602e444f7ead4fb3eafef06eb5",
        "deepnote_cell_type": "text-cell-h2"
      },
      "block_group": "af8cb50101e44e4388f91632069df6c6"
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nfrom time import time\nimport math\nfrom tensorflow import keras\nfrom keras.datasets import cifar10\nfrom torchvision.transforms import Normalize\n\n(train_x, train_y), (test_x, test_y) = cifar10.load_data()",
      "metadata": {
        "source_hash": "f1b33b1d",
        "execution_start": 1729293909957,
        "execution_millis": 5688,
        "execution_context_id": "4e3d0099-2537-4939-b2b9-d36b8f6c7b61",
        "cell_id": "e65b52c75d8f4ffc8a21f6187b6008e6",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 3s 0us/step\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": 13,
      "block_group": "cf2970e3b0184f3e894c768167f9dcd3",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# import numpy as np\n# import tensorflow as tf\n# from time import time\n# import math\n# from include.data import get_data_set\n# from include.model import model, lr\n \n# train_x, train_y = get_data_set(\"train\")\n# test_x, test_y = get_data_set(\"test\")\ntf.set_random_seed(21)\nx, y, output, y_pred_cls, global_step, learning_rate = model()\nglobal_accuracy = 0\nepoch_start = 0\n \n# PARAMS\n_BATCH_SIZE = 128\n_EPOCH = 60\n_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n \n# LOSS AND OPTIMIZER\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n                                   beta1=0.9,\n                                   beta2=0.999,\n                                   epsilon=1e-08).minimize(loss, global_step=global_step)\n \n# PREDICTION AND ACCURACY CALCULATION\ncorrect_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n \n# SAVER\nmerged = tf.summary.merge_all()\nsaver = tf.train.Saver()\nsess = tf.Session()\ntrain_writer = tf.summary.FileWriter(_SAVE_PATH, sess.graph)\n  \ntry:\n    print(\"Trying to restore last checkpoint ...\")\n    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n    saver.restore(sess, save_path=last_chk_path)\n    print(\"Restored checkpoint from:\", last_chk_path)\nexcept ValueError:\n    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n    sess.run(tf.global_variables_initializer())\n  \ndef train(epoch):\n    global epoch_start\n    epoch_start = time()\n    batch_size = int(math.ceil(len(train_x) / _BATCH_SIZE))\n    i_global = 0\n \n    for s in range(batch_size):\n        batch_xs = train_x[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n        batch_ys = train_y[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n \n        start_time = time()\n        i_global, _, batch_loss, batch_acc = sess.run(\n            [global_step, optimizer, loss, accuracy],\n            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)})\n        duration = time() - start_time\n \n        if s % 10 == 0:\n            percentage = int(round((s/batch_size)*100))\n \n            bar_len = 29\n            filled_len = int((bar_len*int(percentage))/100)\n            bar = '=' * filled_len + '>' + '-' * (bar_len - filled_len)\n \n            msg = \"Global step: {:>5} - [{}] {:>3}% - acc: {:.4f} - loss: {:.4f} - {:.1f} sample/sec\"\n            print(msg.format(i_global, bar, percentage, batch_acc, batch_loss, _BATCH_SIZE / duration))\n \n    test_and_save(i_global, epoch)\n  \ndef test_and_save(_global_step, epoch):\n    global global_accuracy\n    global epoch_start\n \n    i = 0\n    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n    while i < len(test_x): \n        j = min(i + _BATCH_SIZE, len(test_x)) \n        batch_xs = test_x[i:j, :] \n        batch_ys = test_y[i:j, :] \n        predicted_class[i:j] = sess.run( \n            y_pred_cls, \n            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)} \n            ) \n        i = j \n        correct = (np.argmax(test_y, axis=1) == predicted_class) \n        acc = correct.mean()*100 \n        correct_numbers = correct.sum() \n        hours, rem = divmod(time() - epoch_start, 3600) \n        minutes, seconds = divmod(rem, 60) \n        mes = \" Epoch {} - accuracy: {:.2f}% ({}/{}) - time: {:0>2}:{:0>2}:{:05.2f}\"\n    print(mes.format((epoch+1), acc, correct_numbers, len(test_x), int(hours), int(minutes), seconds))\n \n    if global_accuracy != 0 and global_accuracy < acc: \n        summary = tf.Summary(value=[ tf.Summary.Value(tag=\"Accuracy/test\", simple_value=acc), ]) \n        train_writer.add_summary(summary, _global_step) \n        saver.save(sess, save_path=_SAVE_PATH, global_step=_global_step) \n        mes = \"This epoch receive better accuracy: {:.2f} > {:.2f}. Saving session...\"\n        print(mes.format(acc, global_accuracy))\n        global_accuracy = acc\n \n    elif global_accuracy == 0:\n        global_accuracy = acc\n \n    print(\"###########################################################################################################\")\n  \ndef main():\n    train_start = time()\n \n    for i in range(_EPOCH):\n        print(\"Epoch: {}/{}\".format((i+1), _EPOCH))\n        train(i)\n \n    hours, rem = divmod(time() - train_start, 3600)\n    minutes, seconds = divmod(rem, 60)\n    mes = \"Best accuracy pre session: {:.2f}, time: {:0>2}:{:0>2}:{:05.2f}\"\n    print(mes.format(global_accuracy, int(hours), int(minutes), seconds))\n  \nif __name__ == \"__main__\":\n    main()\n  \nsess.close()",
      "metadata": {
        "source_hash": "6a97c5ac",
        "execution_start": 1729293965637,
        "execution_millis": 58,
        "execution_context_id": "4e3d0099-2537-4939-b2b9-d36b8f6c7b61",
        "cell_id": "3b74cf9f496a4b259466a4ad89e886d4",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'set_random_seed'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import tensorflow as tf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from time import time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# train_x, train_y = get_data_set(\"train\")\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# test_x, test_y = get_data_set(\"test\")\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_random_seed\u001b[49m(\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m     11\u001b[0m x, y, output, y_pred_cls, global_step, learning_rate \u001b[38;5;241m=\u001b[39m model()\n\u001b[1;32m     12\u001b[0m global_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"
          ]
        }
      ],
      "outputs_reference": null,
      "execution_count": 14,
      "block_group": "3b74cf9f496a4b259466a4ad89e886d4",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Test Network",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "34494965ea6049f2b6840c246b1948fd",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "55d9c187571a4b1f8c05c6abd51fe0ca"
    },
    {
      "cell_type": "code",
      "source": "test_x, test_y = get_data_set(\"test\")\nx, y, output, y_pred_cls, global_step, learning_rate = model()\n  \n_BATCH_SIZE = 128\n_CLASS_SIZE = 10\n_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n  \nsaver = tf.train.Saver()\nsess = tf.Session()\n  \ntry:\n    print(\"\nTrying to restore last checkpoint ...\")\n    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n    saver.restore(sess, save_path=last_chk_path)\n    print(\"Restored checkpoint from:\", last_chk_path)\nexcept ValueError:\n    print(\"\nFailed to restore checkpoint. Initializing variables instead.\")\n    sess.run(tf.global_variables_initializer())\n  \ndef main():\n    i = 0\n    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n    while i < len(test_x):\n        j = min(i + _BATCH_SIZE, len(test_x))\n        batch_xs = test_x[i:j, :]\n        batch_ys = test_y[i:j, :]\n        predicted_class[i:j] = sess.run(y_pred_cls, feed_dict={x: batch_xs, y: batch_ys})\n        i = j\n \n    correct = (np.argmax(test_y, axis=1) == predicted_class)\n    acc = correct.mean() * 100\n    correct_numbers = correct.sum()\n    print()\n    print(\"Accuracy on Test-Set: {0:.2f}% ({1} / {2})\".format(acc, correct_numbers, len(test_x)))\n  \nif __name__ == \"__main__\":\n    main()\n  \nsess.close()",
      "metadata": {
        "cell_id": "3dd61d3d9feb4ea7b39266ec14062461",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "f2889f6685f54c988f2926a622b2aee3",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3e480598-2102-4b3c-a7af-02aec7eef77c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "5874400f808e4ac9a69d39ec3de827b0",
    "deepnote_execution_queue": []
  }
}