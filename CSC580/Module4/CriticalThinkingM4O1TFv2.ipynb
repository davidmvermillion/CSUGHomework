{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Toxicology Testing\nFor this assignment, you will use a chemical dataset to train a neural network to predict human reaction to exposure to certain compounds.",
      "metadata": {
        "cell_id": "c5c97efa1847424fb10031812940dcb2",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "381b84b28cab4bad969df05a10bcdff7"
    },
    {
      "cell_type": "markdown",
      "source": "# Import Packages",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "0df5b6bff8fa42839db2f0ea456e63d8",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "9ae76beabf244a029de57115454ee990"
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport deepchem as dc\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow import keras\nfrom keras import layers",
      "metadata": {
        "source_hash": "6ddd5846",
        "execution_start": 1728154823773,
        "execution_millis": 1,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "570a085413dc4f428ddc898e23621f8d",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 8,
      "block_group": "c979411079224387bd11da34125aefe0",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Set Environment",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "f85f1142eda449918059f22934c76853",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "d720096bb82a46d6a91e57fc2a68730b"
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(456)\ntf.random.set_seed(456)",
      "metadata": {
        "source_hash": "8ddb28f9",
        "execution_start": 1728153658056,
        "execution_millis": 1,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "5eb0c5979d954069bc7afb029a3a3940",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 3,
      "block_group": "c8ce7f88e3b74c7fae77cd6ee2c7f008",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Load and Prep Data",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "8b175493c5b84fdda863b51342e2e1df",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "0efed4883c004f7b872547e2566c42e7"
    },
    {
      "cell_type": "code",
      "source": "_, (train, valid, test), _ = dc.molnet.load_tox21()\ntrain_X, train_y, train_w = train.X, train.y, train.w\nvalid_X, valid_y, valid_w = valid.X, valid.y, valid.w\ntest_X, test_y, test_w = test.X, test.y, test.w\ntrain_y = train_y[:, 0]\nvalid_y = valid_y[:, 0]\ntest_y = test_y[:, 0]\ntrain_w = train_w[:, 0]\nvalid_w = valid_w[:, 0]\ntest_w = test_w[:, 0]",
      "metadata": {
        "source_hash": "7053d93c",
        "execution_start": 1728153661462,
        "execution_millis": 86,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "66ada6b2174847ef9efdd1b0ac7a320e",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 4,
      "block_group": "16d066b06ad1427888bd5eb4abf94428",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Significant Modification\nCode originally written for Tensorflow v1, which has been deprecated for years. For this assignment, we will use Tensorflow v2. Re-writing the entire architecture, paying attention to the steps in the assignment, rather than the starter code. Will also be using Keras sequential architectures. One hint comes from [here](https://www.geeksforgeeks.org/hidden-layer-perceptron-in-tensorflow/).",
      "metadata": {
        "cell_id": "00d19a5c8acc4ee0883602f1344ff948",
        "deepnote_cell_type": "markdown"
      },
      "block_group": "1f734647129c4a369edf4af2541f08d6"
    },
    {
      "cell_type": "markdown",
      "source": "# Define Model Placeholders",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "9abd2561be114cf791f6192da0a2b156",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "f6ecd8301d31497c90c39d76b5710d3b"
    },
    {
      "cell_type": "code",
      "source": "d = 1024\nn_hidden = 50\nlearning_rate = .001\nn_epochs = 10\nbatch_size = 100",
      "metadata": {
        "source_hash": "8c1d0383",
        "execution_start": 1728154839565,
        "execution_millis": 3,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "8704cf2e348143f1a2f277b39d87a231",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 10,
      "block_group": "b796518bec0c44258aaf7b92e2532e06",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Create Model Architecture",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "7b5d0a11547d40a59cddc3c2b8066dd5",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "98cc39b453124256980e09699967eaf4"
    },
    {
      "cell_type": "code",
      "source": "model = keras.Sequential([ \n\tlayers.Dense(256, activation = 'relu', input_shape = [d]), \n\tlayers.BatchNormalization(), \n\tlayers.Dense(256, activation = 'relu'), \n\tlayers.Dropout(0.3), \n\tlayers.BatchNormalization(), \n\tlayers.Dense(7, activation = 'sigmoid') \n]) \n\nmodel.compile( \n\tloss = 'categorical_crossentropy', \n\toptimizer = 'adam', \n\tmetrics = ['AUC'] \n) \n\nmodel.summary()",
      "metadata": {
        "source_hash": "34326121",
        "execution_start": 1728154966958,
        "execution_millis": 55,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "3b3be02cacb74dd0a9931ccbd99c8ad8",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_3 (Dense)             (None, 256)               262400    \n                                                                 \n batch_normalization_2 (Batc  (None, 256)              1024      \n hNormalization)                                                 \n                                                                 \n dense_4 (Dense)             (None, 256)               65792     \n                                                                 \n dropout_1 (Dropout)         (None, 256)               0         \n                                                                 \n batch_normalization_3 (Batc  (None, 256)              1024      \n hNormalization)                                                 \n                                                                 \n dense_5 (Dense)             (None, 7)                 1799      \n                                                                 \n=================================================================\nTotal params: 332,039\nTrainable params: 331,015\nNon-trainable params: 1,024\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": 12,
      "block_group": "48be0abff80b4b659888d214f9a3776f",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Implement Mini-Batch Training",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "c6e39e99f8f148768c2edadabf337321",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "f1e2e60003994641a63fda0a076d6273"
    },
    {
      "cell_type": "code",
      "source": "model.fit(train_X, train_y, \n          epochs = n_epochs, \n          batch_size = batch_size, \n          verbose = 1, \n          validation_data = (valid_X, valid_y)) ",
      "metadata": {
        "source_hash": "4d0f4c0b",
        "execution_start": 1728155461070,
        "execution_millis": 204,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "d9fd80ce2063495795b0768338ddb962",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 7) are incompatible\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_file50smkmsm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 7) are incompatible\n"
          ]
        }
      ],
      "outputs_reference": null,
      "execution_count": 17,
      "block_group": "d399239fc18940b999778bf0e10c8712",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "train_writer = tf.summary.FileWriter('/tmp/fcnet-tox21',\n                                     tf.get_default_graph())\nN = train_X.shape[0]\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    step = 0\n\nfor epoch in range(n_epochs):\n    pos = 0\n\nwhile N > pos:\n\n      batch_X = train_X[pos:pos+batch_size]\n      batch_y = train_y[pos:pos+batch_size]\n      feed_dict = {x: batch_X, y: batch_y}\n      _, summary, loss = sess.run([train_op, merged, l], feed_dict = feed_dict)\n      print(\"epoch %d, step %d, loss: %f\" % (epoch, step, loss))\n      train_writer.add_summary(summary, step)\n\n      step += 1\n      pos += batch_size\n\n# Make Predictions\nvalid_y_pred = sess.run(y_pred, feed_dict={x: valid_X})",
      "metadata": {
        "source_hash": "1ac011ad",
        "execution_start": 1728155194542,
        "execution_millis": 0,
        "execution_context_id": "109c2aa1-6325-4074-a559-ac61333bfedf",
        "cell_id": "0df617c3647f4a0d991345a808747775",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorboard.summary._tf.summary' has no attribute 'FileWriter'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_writer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileWriter\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/fcnet-tox21\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                      tf\u001b[38;5;241m.\u001b[39mget_default_graph())\n\u001b[1;32m      3\u001b[0m N \u001b[38;5;241m=\u001b[39m train_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorboard.summary._tf.summary' has no attribute 'FileWriter'"
          ]
        }
      ],
      "outputs_reference": null,
      "execution_count": 16,
      "block_group": "2999753ca8764473b4e30cc5052bf797",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2c4d82d2-b129-4486-baa4-05c502f179ef' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "d439b7d0b88d4ddbba57dbd2a80a0096",
    "deepnote_execution_queue": []
  }
}